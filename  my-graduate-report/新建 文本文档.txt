We can track the roots of clouds computing by observing the advancement of
several technologies, especially in hardware (virtualization, multi-core chips),
Internet technologies (Web services, service-oriented architectures, Web 2.0),
distributed computing (clusters, grids), and systems management (autonomic
computing, data center automation). Figure 1.1 shows the convergence of
technology fields that significantly advanced and contributed to the advent
of cloud computing.
Some of these technologies have been tagged as hype in their early stages
of development; however, they later received significant attention from
academia and were sanctioned by major industry players. Consequently, a
specification and standardization process followed, leading to maturity and
wide adoption. The emergence of cloud computing itself is closely linked to
the maturity of such technologies. We present a closer look at the technologies
that form the base of cloud computing, with the aim of providing a
clearer picture of the cloud ecosystem as a whole.
我们可以跟踪通过观察的进步，云计算的根技术，特别是在硬件（虚拟化，多核心芯片），
互联网技术（Web服务，面向服务的架构和Web 2.0），分布式计算（集群，网格），系统管理（自主
计算，数据中心自动化）。图1.1显示了收敛技术领域，先进和贡献的到来云计算。
这些技术都被标记为炒作的早期阶段的发展，但是，他们后来收到重大关注学术界和被认可的主要业者。因此，一个
规范和标准化进程，导致成熟，广泛采用。云计算的出现，本身有着密切的联系这种技术的成熟。我们提出了一个仔细看看技术
形式云计算的基础上，目的是提供一个与云生态系统作为一个整体更清晰的画面。

We are currently experiencing a switch in the IT world, from in-house
generated computing power into utility-supplied computing resources delivered
over the Internet as Web services. This trend is similar to what occurred about a
century ago when factories, which used to generate their own electric power,
realized that it is was cheaper just plugging their machines into the newly
formed electric power grid
目前，我们正在经历一个开关，在IT界，从内部生成的计算能力，为公用事业提供的计算资源交付
在Internet上的Web服务。这种趋势是类似发生在大约一个世纪前，当工厂，用于生成自己的电力，
意识到这是更便宜的只需插入到新的机器形成电网.
Computing delivered as a utility can be defined as “on demand delivery of
infrastructure, applications, and business processes in a security-rich, shared,
scalable, and based computer environment over the Internet for a fee”
计算交付作为一种实用工具，可以被定义为“按需交付安全性丰富，共享的基础设施，应用程序和业务流程的，
可扩展的，基于在互联网上的计算机环境的费用“
This model brings benefits to both consumers and providers of IT services.
Consumers can attain reduction on IT-related costs by choosing to obtain
cheaper services from external providers as opposed to heavily investing on IT
infrastructure and personnel hiring. The “on-demand” component of this
model allows consumers to adapt their IT usage to rapidly increasing or
unpredictable computing needs.
这种模式带来的IT服务供应商和消费者的利益。消费者可以达到减少对IT相关成本的选择，以获得
更便宜的服务，而不是从外部供应商的大力投资IT基础设施和人员聘用。 “需求”的组成部分
模式可以让消费者适应他们的IT使用量迅速增加或不可预知的计算需求。
Providers of IT services achieve better operational costs; hardware and
software infrastructures are built to provide multiple solutions and serve many
users, thus increasing efficiency and ultimately leading to faster return on
investment (ROI) as well as lower total cost of ownership (TCO)
供应商的IT服务实现更好的运营成本，硬件和软件基础设施的建立提供了多种解决方案，并为许多
用户，从而提高了效率，并最终导致更快的回报投资回报（ROI）和更低的总拥有成本（TCO）
Several technologies have in some way aimed at turning the utility computing
concept into reality. In the 1970s, companies who offered common data
processing tasks, such as payroll automation, operated time-shared mainframes
as utilities, which could serve dozens of applications and often operated close
to 100% of their capacity. In fact, mainframes had to operate at very high
utilization rates simply because they were very expensive and costs should be
justified by efficient usage
有几种技术已经在某种程度上旨在将效用计算概念变成了现实。在20世纪70年代，公司提供了常见的数据
处理任务，如工资自动化，操作时间共享主机实用程序，它可以为许多应用程序提供服务，往往接近设计
其容量的100％。事实上，大型机不得不工作在非常高使用率只是因为他们是非常昂贵的，费用应该是
合理有效地使用
The mainframe era collapsed with the advent of fast and inexpensive
microprocessors and IT data centers moved to collections of commodity
servers. Apart from its clear advantages, this new model inevitably led to
isolation of workload into dedicated servers, mainly due to incompatibilities 
between software stacks and operating systems [11]. In addition, the unavailability
of efficient computer networks meant that IT infrastructure should be
hosted in proximity to where it would be consumed. Altogether, these facts
have prevented the utility computing reality of taking place on modern
computer systems.
倒塌的大型机时代的来临，快速和廉价的微处理器和IT数据中心转移到大宗商品的集合
服务器。除了其明显的优势，这种新的模式不可避免地导致隔离到专用服务器，主要是由于不兼容的工作量
软件协议栈和操作系统的[11]。此外，不可用高效的计算机网络意味着IT基础设施应
寄存在接近它会被消耗掉。总之，这些事实防止发生在现代的现实效用计算的计算机系统。
Similar to old electricity generation stations, which used to power individual
factories, computing servers and desktop computers in a modern organization
are often underutilized, since IT infrastructure is configured to handle theoretical
demand peaks. In addition, in the early stages of electricity generation,
electric current could not travel long distances without significant voltage
losses. However, new paradigms emerged culminating on transmission systems
able to make electricity available hundreds of kilometers far off from where it is
generated. Likewise, the advent of increasingly fast fiber-optics networks has
relit the fire, and new technologies for enabling sharing of computing power
over great distances have appeared.
与旧的发电站，用于功率个人在一个现代组织的工厂，计算服务器和台式电脑
往往没有得到充分利用，因为IT基础设施的配置，以处理理论
需求高峰。此外，在发电的早期阶段，没有显著电压，电流不能长途跋涉
的损失。然而，新的模式出现高潮传输系统能，使电力可以从那里几百公里远的关
生成的。同样地，随着越来越快的光纤网络重新点燃了火，和新技术，使计算能力的共享
在很远的距离已经出现。
These facts reveal the potential of delivering computing services with
the speed and reliability that businesses enjoy with their local machines. The
benefits of economies of scale and high utilization allow providers to offer
computing services for a fraction of what it costs for a typical company that
generates its own computing power.
这些事实表明提供计算服务的潜力的速度和可靠性，企业享受与本地计算机上。 “
经济规模和利用率高的好处允许服务提供商提供一个典型的公司，它的成本的一小部分计算服务
生成自己的计算能力
1.2.2 SOA, Web Services, Web 2.0, and Mashups
The emergence of Web services (WS) open standards has significantly contributed
to advances in the domain of software integration [12]. Web services
can glue together applications running on different messaging product platforms,
enabling information from one application to be made available to
others, and enabling internal applications to be made available over the
Internet.
Web服务（WS）开放标准的出现，大大贡献的软件集成[12]在域中的进步。 Web服务
可以粘合在一起不同的通讯产品平台上运行的应用程序，
使从一个应用程序中的信息，将提供给其他人，和使内部应用程序被提供在因特网。
Over the years a rich WS software stack has been specified and standardized,
resulting in a multitude of technologies to describe, compose, and orchestrate
services, package and transport messages between services, publish and discover
services, represent quality of service (QoS) parameters, and ensure
security in service access
多年来丰富的WS软件堆栈已被指定和标准化，在众多的技术来形容，组成和安排
服务，包装和运输之间的信息服务，发布和发现服务，表示服务质量（QoS）参数，并确保
服务访问的安全性

WS standards have been created on top of existing ubiquitous technologies
such as HTTP and XML, thus providing a common mechanism for delivering
services, making them ideal for implementing a service-oriented architecture
(SOA). The purpose of a SOA is to address requirements of loosely coupled,
standards-based, and protocol-independent distributed computing. In a SOA,
software resources are packaged as “services,” which are well-defined, selfcontained
modules that provide standard business functionality and are
independent of the state or context of other services. Services are described
in a standard definition language and have a published interface.
WS顶部现有的无处不在的技术标准上已经创建如HTTP和XML，从而提供了一个共同的机制提供
服务，从而使它们适合用于实施面向服务的体系结构（SOA）。一个SOA的目的是要解决的松散耦合的要求，
基于标准的，独立于协议的分布式计算。在SOA中，软件资源打包“服务”，这是很好的定义，selfcontained
提供标准的商务功能和模块独立于其他服务的状态或上下文。服务描述在一个标准的定义语言和发布的接口.
The maturity of WS has enabled the creation of powerful services that can be
accessed on-demand, in a uniform way. While some WS are published with the
intent of serving end-user applications, their true power resides in its interface
being accessible by other services. An enterprise application that follows the
SOA paradigm is a collection of services that together perform complex
business logic
成熟的WS启用，可以创建功能强大的服务访问的需求，以统一的方式。虽然有些WS公布的
服务的最终用户应用程序的意图，其真正的权力在其界面访问其他服务。后面的企业应用程序
SOA范式是一家集服务，共同执行复杂的业务逻辑。
This concept of gluing services initially focused on the enterprise Web, but
gained space in the consumer realm as well, especially with the advent of Web
2.0. In the consumer Web, information and services may be programmatically
aggregated, acting as building blocks of complex compositions, called service
mashups. Many service providers, such as Amazon, del.icio.us, Facebook, and
Google, make their service APIs publicly accessible using standard protocols
such as SOAP and REST [14]. Consequently, one can put an idea of a fully
functional Web application into practice just by gluing pieces with few lines
of code.
这一概念的粘合服务最初集中于企业网站，但有了空间在消费领域以及，特别是进入网站
2。在消费者网络，信息和服务的可编程汇总，作为基石，成分复杂，称为服务
混搭。许多服务供应商，如亚马逊，del.icio.us，脸谱网，和谷歌，使他们的服务API公开访问使用标准协议
如肥皂和休息[ 14 ]。因此，我们可以把一个想法，一个完全功能网络应用到实践的粘合件几行代码。
In the Software as a Service (SaaS) domain, cloud applications can be built
as compositions of other services from the same or different providers. Services
such user authentication, e-mail, payroll management, and calendars are
examples of building blocks that can be reused and combined in a business
solution in case a single, ready-made system does not provide all those features.
Many building blocks and solutions are now available in public marketplaces.
For example, Programmable Web1 is a public repository of service APIs and
mashups currently listing thousands of APIs and mashups. Popular APIs such
as Google Maps, Flickr, YouTube, Amazon eCommerce, and Twitter, when
combined, produce a variety of interesting solutions, from finding video game
retailers to weather maps. Similarly, Salesforce.com’s offers AppExchange,2
which enables the sharing of solutions developed by third-party developers on
top of Salesforce.com components.
在软件即服务（萨斯）域，云应用程序可以建立作为成分的其他服务从相同或不同的供应商。服务
这样的用户认证，电子邮件，薪资管理，和日历例子积木可重复使用，结合在一个业务
解决办法的情况下一个单一的，现成的制度并没有提供所有这些功能。
许多建筑材料和解决方案现在可以在公共市场。例如，可编程web1是一个公共库服务API和
混搭目前上市的数以千计的API和混搭。流行的API等作为谷歌地图，照片，视频，亚马逊电子商务，和推特，当
结合，产生了各种有趣的解决方案，从发现的视频游戏零售商天气图。同样，Sales force。网站提供了appexchange，2
使共享解决方案开发的第三方开发者顶部salesforce.com组件。
1.2.3 Grid Computing
Grid computing enables aggregation of distributed resources and transparently
access to them. Most production grids such as TeraGrid [15] and EGEE [16]
seek to share compute and storage resources distributed across different
administrative domains, with their main focus being speeding up a broad
range of scientific applications, such as climate modeling, drug design, and
protein analysis.
网格计算可以分配资源和透明
访问他们。大多数生产网格如万亿网格[ 15 ]和[ 16 ]乙二醇乙醚
寻求分享计算和存储资源分布在不同的行政领域，其主要重点是加快广阔
应用范围，如气候建模，药物设计，和蛋白质分析。
A key aspect of the grid vision realization has been building standard Web
services-based protocols that allow distributed resources to be “discovered,
accessed, allocated, monitored, accounted for, and billed for, etc., and in
general managed as a single virtual system.” The Open Grid Services Architecture
(OGSA) addresses this need for standardization by defining a set of core
capabilities and behaviors that address key concerns in grid systems.
一个关键方面的网格实现了网站建设标准
服务协议，允许分布式资源被发现，
访问，分配，监测，占，和帐单，等等，并在
一般管理作为一个单一的虚拟系统的开放网格服务架构。”
（也）解决了这一标准化的需要确定一套核心
能力和行为，解决关键问题在网格系统。
Globus Toolkit [18] is a middleware that implements several standard Grid
services and over the years has aided the deployment of several service-oriented
Grid infrastructures and applications. An ecosystem of tools is available to
interact with service grids, including grid brokers, which facilitate user interaction
with multiple middleware and implement policies to meet QoS needs.
网格[ 18 ]是一个中间件，实现了几个标准的网格
服务和多年来辅助部署几个服务
网格基础设施和应用。一个系统的工具可用
互动服务网格，包括网格经纪，便于用户交互
与多个中间件和执行政策，满足服务质量需求。
The development of standardized protocols for several grid computing
activities has contributed―theoretically―to allow delivery of on-demand
computing services over the Internet. However, ensuring QoS in grids has
been perceived as a difficult endeavor [19]. Lack of performance isolation
has prevented grids adoption in a variety of scenarios, especially on environments
where resources are oversubscribed or users are uncooperative. Activities
associated with one user or virtual organization (VO) can influence, in an
uncontrollable way, the performance perceived by other users using the same
platform. Therefore, the impossibility of enforcing QoS and guaranteeing
execution time became a problem, especially for time-critical applications.
发展标准化协议的几个网格计算
活动contributed-theoretically-to允许提供点播
计算服务在互联网上。然而，确保了在网格
被认为是一个困难的工作[ 19 ]。缺乏隔离性能
通过阻止了网格中的各种情况，特别是对环境
在资源超额认购或用户不合作。活动
与一个用户或虚拟组织（旁白）可以影响，在
无法控制的方式，性能感知其他用户使用相同的
公交车站台。因此，不可能执行质量保证
执行时间成了一个问题，特别是对时间敏感的应用。
Another issue that has lead to frustration when using grids is the availability
of resources with diverse software configurations, including disparate operating
systems, libraries, compilers, runtime environments, and so forth. At the same
time, user applications would often run only on specially customized environments.
Consequently, a portability barrier has often been present on most
grid infrastructures, inhibiting users of adopting grids as utility computing
environments.
另一个问题，导致挫折时，使用网格的可用性
资源与不同的软件配置，包括不同的操作
系统，图书馆，编译器，运行时环境，等等。在同一
时间，用户应用程序通常只在特别定制的环境。
因此，一个携带的障碍往往是目前最
网格基础设施，抑制用户采用网格的实用计算
环境的。
Virtualization technology has been identified as the perfect fit to issues that
have caused frustration when using grids, such as hosting many dissimilar
software applications on a single physical platform. In this direction, some
research projects (e.g., Globus VirtualWorkspaces [20]) aimed at evolving grids
to support an additional layer to virtualize computation, storage, and network
resources.
虚拟化技术已被确定为完美的结合问题
造成挫折时，使用网格，托管等许多不同的
软件应用程序在一个单一的物理平台。在这方面，一些
研究项目（例如，球virtualworkspaces [ 20 ]）针对不断变化的网格
支持一个额外的层虚拟化计算，存储，和网络
资源。

1.2.5 Hardware Virtualization
Cloud computing services are usually backed by large-scale data centers
composed of thousands of computers. Such data centers are built to serve
many users and host many disparate applications. For this purpose, hardware
virtualization can be considered as a perfect fit to overcome most operational
issues of data center building and maintenance.
云计算服务通常是由大型数据中心

由成千上万的电脑。这些数据中心，是建立在服务

许多用户和主机的许多不同的应用程序。为此，五金

虚拟化可以被视为一个完美的配合，克服了大部分操作

问题的数据中心的建设与维护。
The idea of virtualizing a computer system’s resources, including processors,
memory, and I/O devices, has been well established for decades, aiming at
improving sharing and utilization of computer systems [21]. Hardware virtualization
allows running multiple operating systems and software stacks on a
single physical platform. As depicted in Figure 1.2, a software layer, the virtual
machine monitor (VMM), also called a hypervisor, mediates access to the
physical hardware presenting to each guest operating system a virtual machine
(VM), which is a set of virtual platform interfaces.
观念的虚拟化计算机系统的资源，包括处理器，

存储器，以及输入/输出设备，以及已建立了几十年，针对

改进的共享和利用计算机系统[ 21 ]。硬件虚拟化

允许同时运行多个操作系统和软件堆栈上

单一的物理平台。如图1.2所示，一个软件层，虚拟

机监控程序（程序），也被称为一个管理程序，介导的访问

物理硬件介绍给每一个客户操作系统虚拟机

（虚拟机），这是一套虚拟平台接口。
The advent of several innovative technologies―multi-core chips, paravirtualization,
hardware-assisted virtualization, and live migration of VMs―has
contributed to an increasing adoption of virtualization on server systems.
Traditionally, perceived benefits were improvements on sharing and utilization,
better manageability, and higher reliability. More recently, with the adoption of
virtualization on a broad range of server and client systems, researchers and
practitioners have been emphasizing three basic capabilities regarding management of workload in a virtualized system, 
namely isolation, consolidation,and migration.
出现一些创新technologies-multi-core芯片，半虚拟化，

硬件虚拟化，生活vms-has迁移

有助于通过增加虚拟服务器系统。

传统上，知觉的好处是改善共享和利用，

更好的管理，和更高的可靠性。最近，通过

虚拟化在一个范围广泛的服务器和客户端系统，研究人员和

医生一直强调三个基本能力管理的工作量在一个虚拟化系统，

即隔离，巩固，和迁移。
Workload isolation is achieved since all program instructions are fully
confined inside a VM, which leads to improvements in security. Better
reliability is also achieved because software failures inside one VM do not
affect others [22]. Moreover, better performance control is attained since
execution of one VM should not affect the performance of another VM.
负荷隔离是因为所有的程序指令是完全

限于在一个虚拟机，从而导致改善安全。更好的

可靠性也由于软件故障在一个虚拟机不

对别人的影响[ 22 ]。此外，更好的性能控制是实现自

执行一个虚拟机不应影响性能的另一个虚拟机。
The consolidation of several individual and heterogeneous workloads onto a
single physical platform leads to better system utilization. This practice is also
employed for overcoming potential software and hardware incompatibilities in
case of upgrades, given that it is possible to run legacy and new operation
systems concurrently.
巩固一些个人和异构工作量到

单一的物理平台导致更好的利用系统。这种做法也是

用于克服潜在的软件和硬件不兼容

案件的升级，因为这是有可能运行的传统和新的操作

系统的同时。
Workload migration, also referred to as application mobility [23], targets at
facilitating hardware maintenance, load balancing, and disaster recovery. It is
done by encapsulating a guest OS state within a VM and allowing it to be
suspended, fully serialized, migrated to a different platform, and resumed
immediately or preserved to be restored at a later date [22]. A VM’s state
includes a full disk or partition image, configuration files, and an image of its
RAM
工作负载迁移，也称为移动[ 23 ]，目标

硬件维修方便，负载平衡，和灾难恢复。它是

通过封装客户操作系统的状态在一个虚拟机，并允许它是

悬浮，完全序列化，迁移到一个不同的平台，和恢复

立即或保存恢复在稍后的日期[ 22 ]。虚拟机的状态

包括一个完整的磁盘或分区的形象，配置文件，和图像的

公羊
A number of VMM platforms exist that are the basis of many utility or
cloud computing environments. The most notable ones, VMWare, Xen, and
KVM, are outlined in the following sections.
一些程序平台存在的基础上有许多实用或

云计算环境。最值得注意的，虚拟机，有，和

工具，概述了以下部分。
VMWare ESXi. VMware is a pioneer in the virtualization market. Its ecosystem
of tools ranges from server and desktop virtualization to high-level
management tools [24]. ESXi is a VMM from VMWare. It is a bare-metal
hypervisor, meaning that it installs directly on the physical server, whereas
others may require a host operating system. It provides advanced virtualization
techniques of processor, memory, and I/O. Especially, through memory
ballooning and page sharing, it can overcommit memory, thus increasing the
density of VMs inside a single physical server.
VMware是虚拟化市场的先驱。它的生态系统
从服务器虚拟化和桌面虚拟化，高层次的的工具范围
管理工具[24]。从VMware ESXi的是一个VMM。这是一个裸机
虚拟机管理程序，这意味着它可以直接安装在物理服务器上，而
其他人可能需要一个主机操作系统。它提供了先进的虚拟化
技术的处理器，内存和I / O。特别是，通过内存
气球和页面共享，它可以过量使用内存，从而增加了
在一个单一的物理服务器的虚拟机密度。
Xen. The Xen hypervisor started as an open-source project and has served as a
base to other virtualization products, both commercial and open-source. It has
pioneered the para-virtualization concept, on which the guest operating system,
by means of a specialized kernel, can interact with the hypervisor, thus
significantly improving performance. In addition to an open-source distribution
[25], Xen currently forms the base of commercial hypervisors of a number
of vendors, most notably Citrix XenServer [26] and Oracle VM [27].
在Xen hypervisor开始作为一个开放源代码的项目，并曾担任
其他虚拟化产品，包括商业和开源的基础。它有
首创的半虚拟化的概念，对其中的客户机操作系统，
通过一个专门的内核，可以与虚拟机管理程序，
大大改善性能。除了一个开放源码的分布
[25]目前，Xen的构成的基础上一个数的商业管理程序
供应商，最显着的Citrix XenServer的[26]和Oracle VM[27]。
KVM. The kernel-based virtual machine (KVM) is a Linux virtualization
subsystem. Is has been part of the mainline Linux kernel since version 2.6.20,
thus being natively supported by several distributions. In addition, activities
such as memory management and scheduling are carried out by existing kernel
features, thus making KVM simpler and smaller than hypervisors that take
control of the entire machine [28].
KVM leverages hardware-assisted virtualization, which improves performance
and allows it to support unmodified guest operating systems [29];
currently, it supports several versions of Windows, Linux, and UNIX [28].
基于内核的虚拟机（KVM）是一个Linux的虚拟化
子系统。是已经从版本2.6.20的Linux内核的一部分，
因此原生支持多个版本。此外，活动
内存管理和调度等进行了现有的内核
的功能，从而使的KVM管理程序，以简单和小于
整个机器的控制[28]。
KVM充分利用硬件辅助虚拟化，从而提高性能
并允许它支持未修改的客户操作系统[29];
目前，它支持多个版本的Windows，Linux，和UNIX [28]。
1.2.6 Virtual Appliances and the Open Virtualization Format
An application combined with the environment needed to run it (operating
system, libraries, compilers, databases, application containers, and so forth) is
referred to as a “virtual appliance.” Packaging application environments in the
shape of virtual appliances eases software customization, configuration, and
patching and improves portability. Most commonly, an appliance is shaped as
a VM disk image associated with hardware requirements, and it can be readily
deployed in a hypervisor.
与环境相结合的应用程序需要运行它（操作
系统，图书馆，编译器，数据库，应用程序容器，等等）是
称作为一个“虚拟设备”包装应用环境中的
形状虚拟设备简化了软件定制，配置和
修补和提高了便携性。最常用的是，器具被成形为
一个虚拟机磁盘映像相关的硬件要求，并可以很容易地
部署在虚拟机管理程序。
On-line marketplaces have been set up to allow the exchange of ready-made
appliances containing popular operating systems and useful software combinations,
both commercial and open-source. Most notably, the VMWare virtual
appliance marketplace allows users to deploy appliances on VMWare hypervisors
or on partners public clouds [30], and Amazon allows developers to share
specialized Amazon Machine Images (AMI) and monetize their usage on
Amazon EC2
已设置为允许交换现成的在线交易市场
家电流行的操作系统和实用的软件组合，
商业和开源。最值得注意的是，VMware虚拟
家电市场可以让用户在VMware虚拟机管理程序部署的设备
或合作伙伴的公共云上[30]，和亚马逊允许开发人员共享
专门的Amazon Machine Images（AMI）和赚钱的使用情况
亚马逊EC2
In a multitude of hypervisors, where each one supports a different VM image
format and the formats are incompatible with one another, a great deal of
interoperability issues arises. For instance, Amazon has its Amazon machine
image (AMI) format, made popular on the Amazon EC2 public cloud. Other
formats are used by Citrix XenServer, several Linux distributions that ship with
KVM, Microsoft Hyper-V, and VMware ESX.
在众多的虚拟机管理程序，每一个支持不同的虚拟机映像
格式和与另一个，大量的格式不兼容
互操作性问题就产生了。例如，亚马逊有它的Amazon Machine
图像格式（AMI），在Amazon EC2公共云。其他
思杰的XenServer，几个Linux发行版，随所使用的格式
KVM，微软的Hyper-V和VMware ESX。
In order to facilitate packing and distribution of software to be run on VMs
several vendors, including VMware, IBM, Citrix, Cisco, Microsoft, Dell, and
HP, have devised the Open Virtualization Format (OVF). It aims at being
“open, secure, portable, efficient and extensible” [32]. An OVF package consists
of a file, or set of files, describing the VM hardware characteristics (e.g.,
memory, network cards, and disks), operating system details, startup, and
shutdown actions, the virtual disks themselves, and other metadata containing
product and licensing information. OVF also supports complex packages
composed of multiple VMs (e.g., multi-tier applications).
为了便于包装和分销的VM上运行的软件
几家厂商，包括的VMware，IBM，思杰，思科，微软，戴尔，和
HP，设计了开放虚拟化格式（OVF）。它的目的是作为
“开放，安全，便携，高效和可扩展的”[32]。 OVF包由
一个文件或一组文件，描述了VM的硬件特性（如，
内存，网卡，磁盘），操作系统详细信息，启动，和
关机操作，虚拟磁盘本身和其他元数据包含
产品和许可信息。 OVF还支持复杂的包
组成的多个虚拟机（例如，多层应用程序）
OVF’s extensibility has encouraged additions relevant to management of
data centers and clouds. Mathews et al. [33] have devised virtual machine
contracts (VMC) as an extension to OVF. A VMC aids in communicating and
managing the complex expectations that VMs have of their runtime environment
and vice versa. A simple example of a VMC is when a cloud consumer
wants to specify minimum and maximum amounts of a resource that a VM
needs to function; similarly the cloud provider could express resource limits as a
way to bound resource consumption and costs.
OVF的可扩展性，鼓励增加相关的管理
数据中心和云。 Mathews等人。 [33]设计了一套虚拟机
合约（VMC）的扩展OVF。一个VMC艾滋病的沟通和
管理复杂的虚拟机有自己的运行时环境的期望，
反之亦然。一个简单的例子，一个VMC的是，当云用户
要指定的最小和最大数量的资源，一个虚拟机
需要的功能，同样的云服务提供商可能会为表达资源限制
的方式来绑定资源的消耗和成本。
1.2.7 Autonomic Computing
The increasing complexity of computing systems has motivated research on
autonomic computing, which seeks to improve systems by decreasing human
involvement in their operation. In other words, systems should manage
themselves, with high-level guidance from humans.
日益复杂的计算系统，激励研究
自主计算的，旨在提高系统通过降低人
参与他们的操作。换句话说，系统管理
自己，从人类高层次的指导
Autonomic, or self-managing, systems rely on monitoring probes and
gauges (sensors), on an adaptation engine (autonomic manager) for computing
optimizations based on monitoring data, and on effectors to carry out changes
on the system. IBM’s Autonomic Computing Initiative has contributed to
define the four properties of autonomic systems: self-configuration, selfoptimization,
self-healing, and self-protection. IBM has also suggested a
reference model for autonomic control loops of autonomic managers, called
MAPE-K (Monitor Analyze Plan Execute―Knowledge).
自主，自我管理，系统依靠监控探头，
压力表（传感器），适应发动机的（自主经理）的计算
根据监测数据，优化和效应进行更改
在系统上。 IBM的自主计算计划作出了贡献
定义植物神经系统的四个属性：自我配置，selfoptimization，
自我修复和自我保护。 IBM也提出了
参考模型的自主管理，自主控制回路
MAPE-K（监控分析计划执行的知识）
The large data centers of cloud computing providers must be managed in an
efficient way. In this sense, the concepts of autonomic computing inspire
software technologies for data center automation, which may perform tasks
such as: management of service levels of running applications; management of
data center capacity; proactive disaster recovery; and automation of VM
provisioning.
大型数据中心的云计算供应商必须在管理
有效的方法。从这个意义上说，自主计算的概念启发
软件技术的数据中心自动化，从而可以执行的任务
如：管理管理正在运行的应用程序的服务水平;
数据中心的处理能力，积极的灾难恢复和虚拟机自动化
配置
1.3 LAYERS AND TYPES OF CLOUDS
Cloud computing services are divided into three classes, according to the
abstraction level of the capability provided and the service model of providers,
namely: (1) Infrastructure as a Service, (2) Platform as a Service, and (3) Software
as a Service [6]. Figure 1.3 depicts the layered organization of the cloud stack
from physical infrastructure to applications.
云计算服务分为三个类别，根据
提供的功能和服务的提供者模型的抽象层次，
即：（1）基础设施即服务（2）平台即服务，和（3）软件
作为服务[6]。图1.3描述了云栈的分层组织
从物理基础设施的应用程序。
These abstraction levels can also be viewed as a layered architecture where
services of a higher layer can be composed from services of the underlying layer
[37]. The reference model of Buyya et al. [38] explains the role of each layer in
an integrated architecture. A core middleware manages physical resources and
the VMs deployed on top of them; in addition, it provides the required features
(e.g., accounting and billing) to offer multi-tenant pay-as-you-go services.
Cloud development environments are built on top of infrastructure services
to offer application development and deployment capabilities; in this level,
various programming models, libraries, APIs, and mashup editors enable the
creation of a range of business, Web, and scientific applications. Once deployed
in the cloud, these applications can be consumed by end users.
这些抽象的水平，也可以被看作是一个分层的体系结构，
较高的层的服务可以由从服务的下层
[37]。的参考模型的Buyya等。 [38]说明中的每个层的作用
综合性建筑。一个核心中间件管理物理资源和
虚拟机部署在它们上面，此外，它提供了所需的功能
（例如，会计和计费）提供多租户随收随付你去服务。
云开发环境是建立在基础设施服务的顶部
提供应用程序开发和部署能力，在这个水平，
不同的编程模型，图书馆，原料药，和混搭编辑器启用
创造了一系列的业务，Web和科学应用。一旦部署
在云中，这些应用程序可以食用的最终用户。
1.3.1 Infrastructure as a Service
Offering virtualized resources (computation, storage, and communication) on
demand is known as Infrastructure as a Service (IaaS) . A cloud infrastructure
enables on-demand provisioning of servers running several choices of operating
systems and a customized software stack. Infrastructure services are considered
to be the bottom layer of cloud computing systems .
提供虚拟化的资源（计算，存储和通信）
被称为基础设施即服务（IaaS）的需求。云基础设施
实现按需配置的服务器上运行的操作系统的多种选择
系统和定制的软件堆栈。被认为是基础设施服务
是云计算系统的底层。

Amazon Web Services mainly offers IaaS, which in the case of its EC2
service means offering VMs with a software stack that can be customized
similar to how an ordinary physical server would be customized. Users are
given privileges to perform numerous activities to the server, such as: starting
and stopping it, customizing it by installing software packages, attaching
virtual disks to it, and configuring access permissions and firewalls rules.
亚马逊网络服务主要提供的IaaS，在其EC2的情况下，
服务是指提供一个软件栈，它可以自定义虚拟机
类似于普通的物理服务器进行定制。用户是
给定的权限来执行许多活动的服务器，如：启动
和停止，自定义安装软件包，附加
虚拟磁盘和配置访问权限和防火墙规则。
1.3.2 Platform as a Service
In addition to infrastructure-oriented clouds that provide raw computing and
storage services, another approach is to offer a higher level of abstraction to
make a cloud easily programmable, known as Platform as a Service (PaaS). A
cloud platform offers an environment on which developers create and deploy
applications and do not necessarily need to know how many processors or how
much memory that applications will be using. In addition, multiple programming
models and specialized services (e.g., data access, authentication, and
payments) are offered as building blocks to new applications .
除了提供原始计算和基础设施面向云
仓储服务，另一种方法是提供更高的抽象级别
易于编程，平台即服务（PaaS）被称为一个云。一
云计算平台提供了一个环境，开发人员创建和部署
的应用，不一定需要知道有多少个处理器或
太多的内存，应用程序将使用。此外，多种编程
模式和专业化的服务（例如，数据接入，认证，和
付款）提供新的应用程序构建块。
Google AppEngine, an example of Platform as a Service, offers a scalable
environment for developing and hosting Web applications, which should
be written in specific programming languages such as Python or Java, and use
the services’ own proprietary structured object data store. Building blocks
include an in-memory object cache (memcache), mail service, instant messaging
service (XMPP), an image manipulation service, and integration with Google
Accounts authentication service.
谷歌AppEngine平台即服务的一个例子，提供了一个可扩展的
开发和托管Web应用程序的环境，这应该
在特定的编程语言，如Python或Java编写的，并使用
服务自身的专有结构化对象的数据存储。积木
包括内存中的对象缓存（memcache的），邮件服务，即时通讯
服务（XMPP），图像处理服务，以及集成与谷歌
帐户认证服务。
1.3.3 Software as a Service
Applications reside on the top of the cloud stack. Services provided by this
layer can be accessed by end users through Web portals. Therefore, consumers
are increasingly shifting from locally installed computer programs to on-line
software services that offer the same functionally. Traditional desktop applications
such as word processing and spreadsheet can now be accessed as a service
in the Web. This model of delivering applications, known as Software as a
Service (SaaS), alleviates the burden of software maintenance for customers
and simplifies development and testing for providers.
应用程序驻留在云堆栈的顶部。本所提供的服务，
层可以由最终用户通过Web门户访问。因此，消费者
正越来越多地从本地安装的计算机程序转移到上线
软件服务，提供相同的功能。传统的桌面应用程序
如文字处理和电子表格，现在可以作为服务访问
在网络上。这个模型提供的应用程序，被称为软件即
即服务（SaaS），软件维护，为客户减轻了负担
并简化了对供应商的开发和测试。
Salesforce.com, which relies on the SaaS model, offers business productivity
applications (CRM) that reside completely on their servers, allowing costumers
to customize and access applications on demand.
Salesforce.com是依赖于SaaS模式，提供企业生产力
应用程序（CRM），完全驻留在他们的服务器上，允许的costumers
定制和访问应用程序的需求。
1.3.4 Deployment Models
Although cloud computing has emerged mainly from the appearance of public
computing utilities, other deployment models, with variations in physical
location and distribution, have been adopted. In this sense, regardless of its
service class, a cloud can be classified as public, private, community, or hybrid [6]
based on model of deployment as shown in Figure 1.4.
虽然云计算已经成为主要从外观公共
计算工具，其他的部署模型，在物理变化
位置和分布，已被采纳。在这个意义上，而不管其
服务类，云可分为公立，私立，社区，或混合[6]
根据部署模型如图1.4所示。
Armbrust et al. [5] propose definitions for public cloud as a “cloud made
available in a pay-as-you-go manner to the general public” and private cloud as
“internal data center of a business or other organization, not made available to
the general public.”
armbrust等。 [5]提出的定义，公共云的“云
提供的薪酬去的方式向公众和私有云
“内部数据中心的企业或其他组织，而不是提供给
广大市民。“
In most cases, establishing a private cloud means restructuring an existing
infrastructure by adding virtualization and cloud-like interfaces. This allows
users to interact with the local data center while experiencing the same
advantages of public clouds, most notably self-service interface, privileged
access to virtual servers, and per-usage metering and billing.
在大多数情况下，建立一个私有云，重组现有的
虚拟化和云状的接口通过增加基础设施。这使得
用户进行交互的本地数据中心，同时遇到了同样的
公共云的优势，最显着的自助服务界面，特权
访问虚拟服务器，每次使用的计量和计费。
A community cloud is “shared by several organizations and supports a
specific community that has shared concerns (e.g., mission, security requirements,
policy, and compliance considerations)“
一个社区云“共享一些组织和支持
特定的社会，共享问题（例如，任务，安全要求，
政策，合规性考虑）
A hybrid cloud takes shape when a private cloud is supplemented with
computing capacity from public clouds [7]. The approach of temporarily
renting capacity to handle spikes in load is known as “cloud-bursting”.
私有云混合云的形状，当补充
从公共云的计算能力[7]。暂时的方法
租赁处理高峰负载能力被称为“云突发”